---
title: "forecast challenge"
author: "Shubhi Sharma"
date: "30/06/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Data prep 
targets <-  readr::read_csv("beetles-targets.csv.gz")
abby <- targets[targets$siteID == "DSNY", ]

```

```{r}
# Model 
RandomWalkLN = "
model{
  
  #### Data Model
  for(t in 2:n){
    y[t] ~ dnorm(y[t-1],tau_obs)
  }
  
  #### Process Model
  ##for(t in 2:n){
  ##  x[t]~dnorm(x[t-1],tau_add)
  ##}
  
  #### Priors
  ##x[1] ~ dnorm(x_ic,tau_ic)
  tau_obs ~ dgamma(a_obs,r_obs)
  tau_add ~ dgamma(a_add,r_add)

  ## In sample prediction 
  for(t in 2:n){
    ypred[t] ~ dnorm(y[t-1],tau_obs)
  }
  
}
"
```

# Insert new model 


```{r}
# JAGS set up 
nchain = 3
# y <- abby$abundance + 0.001 # adding a nugget
y <- log(abby$abundance + 0.001)
init <- list()

# log y.samp if y isn't logged!
for(i in 1:nchain){
  y.samp = sample(y,length(y),replace=TRUE)
  init[[i]] <- list(tau_add=1/var(diff((y.samp))),  ## initial guess on process precision
                    tau_obs=5/var((y.samp)))        ## initial guess on obs precision
}



data <- list(y=y,n=length(y),           ## data
            ## x_ic=log(1000),tau_ic=100, ## initial condition prior
             a_obs=1,r_obs=1,           ## obs error prior
             a_add=1,r_add=1            ## process error prior
             )

# JAGS model 
j.model   <- jags.model (file = textConnection(RandomWalkLN),
                         data = data,
                         # inits = init,
                         n.chains = 3)

## burn-in
jags.out   <- coda.samples (model = j.model,
                            variable.names = c("tau_obs", "ypred"),
                            n.iter = 10000)
# plot(jags.out)

```


# Posterior analysis 

```{r}
samples <- as.matrix(jags.out)

time <- abby$time
time.rng = c(1,length(targets$time))       ## adjust to zoom in and out
y.pred <- grep("^y",colnames(samples)) ## grab all columns that start with the letter y
ci <- apply(samples[,y.pred],2,quantile,c(0.025,0.5,0.975)) ## model was fit on log scale

##### Plotting 

# par(mfrow=c(1, 3))
# Just observed data plot
plot(time[-1], ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Log(abundance)", main = "Observed")
## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
points(time[-1],y[-1],pch="+",cex=0.5)
lines(time[-1], y[-1])

# CI plot of fitted model - using all data
plot(time[-1], ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Log(abundance)", main = "Fitted")
## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
ecoforecastR::ciEnvelope(time[-1],ci[1,],ci[3,],col=ecoforecastR::col.alpha("lightBlue",0.75))
points(time[-1],y[-1],pch="+",cex=0.5)
lines(time[-1], y[-1])
points(time[-1], colMeans(samples[, y.pred]), pch = "x", col = "blue")

```

# Forecast 

```{r}
# All 2021 data are NAs

# JAGS set up same as chunk above 
rmdate <- grep("2021",abby$time )
ymiss <- log(abby$abundance + 0.001)
ymiss[rmdate] <- NA


data <- list(y=ymiss,n=length(y),           ## data
            ## x_ic=log(1000),tau_ic=100, ## initial condition prior
             a_obs=1,r_obs=1,           ## obs error prior
             a_add=1,r_add=1            ## process error prior
             )

# JAGS model 
j.model   <- jags.model (file = textConnection(RandomWalkLN),
                         data = data,
                         # inits = init,
                         n.chains = 3)

## burn-in
jags.out   <- coda.samples (model = j.model,
                            variable.names = c("tau_obs", "ypred"),
                            n.iter = 10000)
# plot(jags.out)


# Visualize 

samples <- as.matrix(jags.out)

time <- abby$time
time.rng = c(1,length(targets$time))       ## adjust to zoom in and out
y.pred <- grep("^y",colnames(samples)) ## grab all columns that start with the letter y
ci <- apply(samples[,y.pred],2,quantile,c(0.025,0.5,0.975)) ## model was fit on log scale

plot(time[-1], ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Log(abundance)", main = "Forecast")
## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
ecoforecastR::ciEnvelope(time[-1],ci[1,],ci[3,],col=ecoforecastR::col.alpha("orange",0.75))
points(time[-1],ymiss[-1],pch="+",cex=0.5)
lines(time[-1], ymiss[-1])
points(time[-1], colMeans(samples[,y.pred]), pch = "x", col = "brown")

```

# Comparison of observation error by site 
```{r}
# Insert site name
hist(samples[, 1], main = paste0("DSNY (n=", length(y), ")"))
abline(v = mean(samples[, 1]), col = 'red')
```

# Kalman Filter code 

# Just juse 4 sites - most abundant sites - CPER, OAES, DSNY, OSBS

```{r}

# Need a MV random walk first 

SpatialRandomWalk = "
model{

  #### Data Model
  for(t in 1:n){
    for(i in 1:nsite){
      y[i,t] ~ dnorm(x[i,t],tau_obs)
    }
  }

  #### Process Model
  for(t in 2:n){
    for(i in 1:nsite){
      mu[i,t] <- x[i,t-1] 
    }
    x[1:nsite,t] ~ dmnorm(mu[1:nsite,t],Omega_proc)
  }
  
  #### Priors
  for(i in 1:nsite){
    x[i,1] ~ dnorm(x_ic,tau_ic)
  }
  tau_obs ~ dgamma(a_obs,r_obs)
  Omega_proc ~ dwish(R,k)
  alpha ~ dbeta(1,20)
  
  #### Ypred
  for(t in 1:n){
    for(i in 1:nsite){
      ypred[i,t] ~ dnorm(x[i,t],tau_obs)
    }
  }

}
"
```

# Kalman functions 

```{r}
##'  Kalman Filter
##' @param  M   = model matrix
##' @param  mu0 = initial condition mean vector
##' @param  P0  = initial condition covariance matrix
##' @param  Q   = process error covariance matrix
##' @param  R   = observation error covariance matrix
##' @param  Y   = observation matrix (with missing values as NAs), time as col's
##'
##' @return list
##'  mu.f, mu.a  = state mean vector for (a)nalysis and (f)orecast steps
##'  P.f, P.a    = state covariance matrix for a and f
KalmanFilter <- function(M,mu0,P0,Q,R,Y){
  
  ## storage
  nstates = nrow(Y)  
  nt = ncol(Y)
  mu.f  = matrix(NA,nstates,nt+1)  ## forecast mean for time t
  mu.a  = matrix(NA,nstates,nt)  ## analysis mean for time t
  P.f  = array(NA,c(nstates,nstates,nt+1))  ## forecast variance for time t
  P.a  = array(NA,c(nstates,nstates,nt))  ## analysis variance for time t

  ## initialization
  mu.f[,1] = mu0
  P.f[,,1] = P0
  I = diag(1,nstates)

  ## run updates sequentially for each observation.
  for(t in 1:nt){
  print(paste0("time step: ", t))
    ## Analysis step: combine previous forecast with observed data
    KA <- KalmanAnalysis(mu.f[,t],P.f[,,t],Y[,t],R,H=I,I)
    mu.a[,t] <- KA$mu.a
    P.a[,,t] <- KA$P.a
    
    print(paste0("Analysis step done for time: ", t))
    
    ## Forecast step: predict to next step from current
    KF <- KalmanForecast(mu.a[,t],P.a[,,t],M,Q)
    mu.f[,t+1] <- KF$mu.f
    P.f[,,t+1] <- KF$P.f
  }
   print(paste0("Forecast step done for time: ", t))
  
  return(list(mu.f=mu.f,mu.a=mu.a,P.f=P.f,P.a=P.a))
}

##' Kalman Filter: Analysis step
##' @param  mu.f = Forecast mean (vector)
##' @param  P.f  = Forecast covariance (matrix)
##' @param  Y    = observations, with missing values as NAs) (vector)
##' @param  R    = observation error covariance (matrix)
##' @param  H    = observation matrix (maps observations to states)
KalmanAnalysis <- function(mu.f,P.f,Y,R,H,I){
  obs = !is.na(Y) ## which Y's were observed?
  if(any(obs) ){
    H <- H[obs,]                                              ## observation matrix
    K <- P.f %*% t(H) %*% solve(H%*%P.f%*%t(H) + R[obs,obs])  ## Kalman gain
    mu.a <- mu.f + K%*%(Y[obs] - H %*% mu.f)                  ## update mean
    P.a <- (I - K %*% H)%*%P.f                                ## update covariance
    ## Note: Here's an alternative form that doesn't use the Kalman gain
    ## it is less efficient due to the larger number of matrix inversions (i.e. solve)
    ## P.a <- solve(t(H)%*%solve(R[obs,obs])%*%(H) + solve(P.f))                             
    ## mu.a <- P.a %*% (t(H)%*%solve(R[obs,obs])%*%Y[obs] + solve(P.f)%*%mu.f)
  } else {
    ##if there's no data, the posterior is the prior
    mu.a = mu.f
    P.a = P.f
  }
  return(list(mu.a=mu.a,P.a=P.a))
}

##' Kalman Filter: Forecast Step
##' @param mu.a = analysis posterior mean (vector)
##' @param P.a  = analysis posterior covariance (matrix)
##' @param M    = model (matrix)
##' @param  Q   = process error covariance (matrix)
KalmanForecast <- function(mu.a,P.a,M,Q){
  mu.f = M%*%mu.a
  P.f  = Q + M%*%P.a%*%t(M)
  return(list(mu.f=mu.f,P.f=P.f))
}
```


# Data wrangling 

```{r}
ab <- targets[, c("siteID", "time", "abundance")]
xy <- reshape2::melt(ab, id.vars = c("siteID", "time"))
xy2 <- reshape2::dcast(xy,   time ~ siteID)
xy2$month <- lubridate::floor_date(xy2[, "time"], "month")
xy3 <- subset(xy2,select= -time)
xy3 <- aggregate(xy3, by = list(xy3$month), FUN = mean, data = xy3, na.rm = T )
# rm_ind <- grep("2021", xy3$month)
# xy3[rm_ind, ] <- NA
# subsetting to just 4 sites for now 
# add BART
xysub <- xy3[, c("CPER", "DSNY", "OSBS", "OAES")]


xysub2 <- t(xysub)
xysub3 <- log(xysub2 + 0.0001)
# JAGS set up 
R <- matrix(0, ncol = nrow(xysub3), nrow = nrow(xysub3))
diag(R) <- 1
data <- list(y=xysub3, n=ncol(xysub3),           ## data
            ## x_ic=log(1000),tau_ic=100, ## initial condition prior
             a_obs=1,r_obs=1,           ## obs error prior
            # a_add=1,r_add=1,           ## process error prior
            R = R,                      ## wishart prior
            k = 5,                      ## wishart df prior
            x_ic = 0,                   
            tau_ic = 0.4,
            nsite = nrow(xysub3)
             )

# JAGS model 
j.model   <- jags.model (file = textConnection(SpatialRandomWalk),
                         data = data,
                         # inits = init,
                         n.chains = 3)

## burn-in
jags.out   <- coda.samples (model = j.model,
                            variable.names = c("tau_obs", "ypred", "Omega_proc" ),
                            n.iter = 10000)

# plot(jags.out)

samples <- as.matrix(jags.out)

```


```{r}

## log transform data
Y   = xysub3
# temporary fix
na_count <- colSums(is.na(xysub3))
Y <- xysub3[, c(na_count < 3)]
nsites = nrow(Y)
## options for process model 
# alpha = 0        ## assume no spatial flux
alpha = 0.1   ## assume a large spatial flux
# M = adj*alpha + diag(1-alpha*apply(adj,1,sum))  ## random walk with flux
M = matrix(0, ncol = nrow(xysub3), nrow = nrow(xysub3))
diag(M) <- alpha
## options for process error covariance
#Q = tau_proc            ## full process error covariance matrix
omgea_ind <- grep("^Omega", colnames(samples))
# Q = diag(diag(tau_proc))        ## diagonal process error matrix
Q = matrix(colMeans(samples[, omgea_ind]), nrow = nrow(xysub3), ncol = nrow(xysub3))
Q= solve(Q)
## observation error covariance (assumed independent)  
tau_ind <- grep("^tau", colnames(samples))
 R = diag(mean(1/samples[, tau_ind]), nsites) 
#R = diag(0.2, nsites)

## prior on first step, initialize with long-term mean and covariance
mu0 = apply(Y,1,mean,na.rm=TRUE)
P0 = cov(t(Y),use="pairwise.complete.obs")
#w <- P0*0+0.25 + diag(0.75,dim(P0)) ## iptional: downweight covariances in IC
#P0 = P0*w 

## Run Kalman Filter
M = diag(1,4)
KF00 = KalmanFilter(M,mu0,P0,Q,R,Y)


```

```{r}
attach(KF00)
nt = ncol(Y)
# time = xy3$Group.1[na_count != 3]
time = 1:nt
sites <- colnames(xysub)

### plot ANALYSIS mean & CI time-series
par(mfrow=c(1,4))
for(i in 1:nsites){
  ci = rbind(mu.a[i,]-1.96*sqrt(P.a[i,i,]),mu.a[i,]+1.96*sqrt(P.a[i,i,]))
  plot(time,mu.a[i,],ylim=range(ci,na.rm=TRUE),type='n', main = sites[i],
       ylab = "log(Abundance)", xlab = "Year")
   ecoforecastR::ciEnvelope(time,ci[1,],ci[2,],col="lightBlue")
   lines(time,mu.a[i,],col=4)
   lines(time,Y[i,])
  # points(time)
}


par(mfrow=c(1,4))
for(i in 2){
  ci = rbind(mu.f[i,]-1.96*sqrt(P.f[i,i,]),mu.f[i,]+1.96*sqrt(P.f[i,i,]))
  plot(time,mu.f[i,-1],ylim=range(ci,na.rm=TRUE),type='n', main = sites[i],
       ylab = "log(Abundance)", xlab = "Year")
  ecoforecastR::ciEnvelope(time,ci[1,],ci[2,],col="lightBlue")
  lines(time,mu.f[i,-1],col=4)
  lines(time,Y[i,])
  # points(time)
}


## plot ANALYSIS and FORECAST variance time-series
par(mfrow=c(1,4))
for(i in 1:nsites){
  plot(1:nt,sqrt(P.a[i,i,]),xlab="Time", #ylim=c(0,sqrt(max(c(P.a[i,i,],P.f[i,i,])))),main=sites[i], 
       ylim = c(0, 5),
       ylab="Std Error",type='l')
  lines(time,sqrt(P.f[i,i,1:nt]),col=2)
  points(time[is.na(Y[i,])],rep(0,nt)[is.na(Y[i,])],pch="*",col=3, cex = 3) ## flag's the zero's
  legend("topright",legend=c("Analysis","Forecast","NAs"),col=1:3,lty=c(1,1,NA),pch=c(NA,NA,1),cex=1.4)
}
#
```


